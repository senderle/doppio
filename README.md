# doppio

Doppio is a data prototyping tool for humanities research.

Data in the humanities is often complex and richly interlinked.
One of the simplest relationships relevant to humanists is the relation
of author to book. In a traditional relational database, this already
requires not two but three tables to represent, because one book can 
have many authors, and one author can write many books; a third table
is needed to track the is-an-author-of relation between the other two.

Now suppose that you want to represent not books but theatrical
performances. There may be stagehands, actors, prop managers, playwrights,
set designers, directors, makeup artists, and many other contributors
working together to produce a single performance. Most of these 
individuals contribute to multiple performances, sometimes in one role, 
sometimes in another. A faithful representation of these connections in 
a relational database would require an exceptionally complex schema 
that would almost certainly need to be devleoped and tuned over time 
before it could do its job well.

Doppio provides an alternative approach to that tuning process. Using a
NoSQL database ([MongoDB](https://www.mongodb.com/)) combined with a 
flexible schema validation framework and API generator 
([Eve](https://docs.python-eve.org/en/stable/)), Doppio speeds up the 
process of developing a richly expressive data model suitable for 
humanities data. Doppio schemas are easy to modify and update, so that 
as researchers see and enter more data, they can accommodate new findings
quickly. Doppio schemas are also self-documenting; the data entry form
is automatically rendered in a way that makes the structure of the
underlying schema self-evident, even to users who have never worked with
a database at all.

Once the schema reaches a stable point, it can be used as-is with the 
provided database and API, or it can be used as the basis for a more 
structured relational database. Either way, the API makes it easy to 
access the data for analysis, visualization, exploration, and 
preservation.

#### To come:

### The Doppio philosophy
* Put data first
* Make data accessible
  * Uses human-readable JSON/YAML representations for input and output
  * Provides a built-in API
  * ... more features in the future? ...
* Use self-documenting systems
  * Names of JSON/YAML keys must be descriptive b/c they are also the basis for the data entry form
  * Schema can include documentation which is used in the automatically rendered form
* Bake in good data practices
* Create isomorphic data representations


## Getting Started

-------------------
LOCAL SETUP
-------
In all the following instructions, a value between square braces
(like this: [some_value]) is a placeholder for a value of your choice.
In some cases, this value should be a random string generated by a 
cryptographically secure RNG.

To begin with, in the root directory, create a new folder called .envs:

    $ mkdir .envs

Inside, create a .dockerignore file:

    $ touch .dockerignore

Now, create another directory called .local:

    $ mkdir .local

In it, create three files, .caddy, .eve and .mongo:

    $ touch .caddy
    $ touch .eve
    $ touch .mongo

In .caddy, put

    DOMAIN_NAME=localhost


In .mongo, put

    MONGO_INITDB_ROOT_USERNAME=root
    MONGO_INITDB_ROOT_PASSWORD=[root_password]

`MONGO_INITDB_ROOT_PASSWORD` should be set to a random string generated 
by a cryptographically secure RNG. (If you use LastPass, for example, 
have it generate a random string of more than 20 characters.)

In .eve, put

    EVE_MONGO_USER=[eve_user]
    EVE_MONGO_PASSWORD=[eve_password]
    EVE_TOKEN_SECRET=[random_string]
    EVE_DATABASE_NAME=[your_db_name]

`EVE_MONGO_PASSWORD` and `EVE_TOKEN_SECRET` should both be set to random strings
generated by a cryptographically secure RNG. (If you use LastPass, for 
example, have it generate two random strings of more than 20 characters.)

Your current directory in `.envs` should be

    bash
    ├── .envs
    │   ├── .local
    │   │   ├── .mongo
    │   │   ├── .eve
    │   │   ├── .caddy
    │   ├── .dockerignore
    │
    ├── the rest of the app


Now, build docker-compose from the root directory:

    $ docker-compose build

Before launching the server, we have to create a docker volume called
`playbill-db` as our database with the command below:

    $ docker volume create --name=playbill-db

Now we can launch the server with:

    $ docker-compose up

The server should be up and running. To access the server, use https://localhost.
The homepage is at https://localhost/home


CREATE SUPERUSER
----
A superuser will allow you to log in to and use the features in the web app.

Open a new terminal tab in the root directory of the project. In it, type:

    $ docker ps

to get the list of running containers, and copy the Container ID (the first code)
of the container with the name `pdb_mongo`.

Now, type:

    $ docker exec -it (Container ID) /bin/sh

Where (Container ID) is the id you just copied.

Now, launch the mongo shell inside the docker container as the root user with
the command

    # mongo -u root

You will be prompted for a password. Enter the randomized password you inputted
for `MONGO_INITDB_ROOT_PASSWORD` inside `.mongo`.

Inside the shell, open the relevant database by:

    '> use your_db_name

Where `your_db_name` is the name you assigned to `EVE_DATABASE_NAME` above.

And create a new user with this command, where `[eve_user]` and `[eve_password]`
are the same as the values assigned to `EVE_MONGO_USER` and `EVE_MONGO_PASSWORD`.

    '> db.createUser({user: "[eve_user]", pwd: "[eve_password]", roles: ["readWrite"]})

You can now close the shell.

To add a user to login to the website, run the following command:

    $ docker-compose run --rm eve flask createsuperuser

Enter your username and password and the user will be created. You can create as
many users as desired with this command.

From now on, you should be able to sign in using the username and password(s)
that you created.


EXPORT ENTRIES IN THE DATABASE TO A FOLDER
---
This command will dump each entry currently residing in the database as
its own .json file at the location specified by [output_folder]:

    $ docker-compose run --rm eve flask exportjson [output_folder]

LOAD JSON DATA FROM A FOLDER TO THE DATABASE
---
This command will load json files in the given folder into the
database. It takes a single argument, the name/dir of the folder
containing the .json files. In the below command this is given as 
`input_folder`, but be sure to change this with whatever folder 
you are reading from.

The folder should only contain .json objects using the same schema as
the database.

    $ docker-compose run --rm eve flask readjson [input_folder]

CREATE DATABASE INDICES
---
In order to ensure that records are uniquely identified in a human-readable way,
we need to impose a uniqueness constraint at the database level on a field identified
in `settings.py` for that purpose: `FILENAME_FIELD = 'myIdField`. The way to do this
in Mongo is by creating a unique index on `myIdField`. 

To do this, log into the mongo shell as root (as described above) and follow the
instructions here: https://docs.mongodb.com/manual/core/index-unique/

In the future we might also add a keyword search option that would require you to
create a text search index as described here: https://docs.mongodb.com/manual/text-search/




### Acknowledgements:

This repository contains code from the following repositories:
* https://github.com/senderle/playbill-database-arch
* https://github.com/senderle/pbdb-eve
* https://github.com/senderle/pbdb
* https://github.com/kingtimm/Eve-TokenAuth

And written by the following github users:
* https://github.com/annamarion
* https://github.com/scye09
* https://github.com/SiyuZheng
* https://github.com/ayhanefe
* https://github.com/kingtimm
* https://github.com/senderle

Doppio was created with support from the University of Pennsylvania Libraries, 
the Price Lab for Digital Humanities, and the Andrew W. Mellon Foundation
